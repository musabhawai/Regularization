# Regularization – Ridge, Lasso & Elastic Net

## 📌 Overview
This repository contains examples demonstrating three popular *regularization techniques*:
1. *Ridge Regression (L2 Regularization)* – Reduces model complexity by penalizing large coefficients.
2. *Lasso Regression (L1 Regularization)* – Performs feature selection by shrinking some coefficients to zero.
3. *Elastic Net* – Combines L1 and L2 penalties for balanced regularization.

## 📖 About Regularization
Regularization is a method to *prevent overfitting* in machine learning models by adding a penalty term to the loss function.  
- *Ridge*: Keeps all features but reduces their magnitude.  
- *Lasso*: Eliminates less important features entirely.  
- *Elastic Net*: Offers a trade-off between Ridge and Lasso benefits.

## 🛠 Technologies Used
- Python 
- Pandas
- NumPy
- Matplotlib
- Scikit-Learn

## 📂 Projects Included
### 1️⃣ Ridge Regression
- Predicts target variable while controlling coefficient size using L2 penalty.

### 2️⃣ Lasso Regression
- Performs both prediction and feature selection using L1 penalty.

### 3️⃣ Elastic Net
- Balances between Ridge and Lasso for more robust predictions.
