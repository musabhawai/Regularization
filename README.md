# Regularization â€“ Ridge, Lasso & Elastic Net

## ğŸ“Œ Overview
This repository contains examples demonstrating three popular *regularization techniques*:
1. *Ridge Regression (L2 Regularization)* â€“ Reduces model complexity by penalizing large coefficients.
2. *Lasso Regression (L1 Regularization)* â€“ Performs feature selection by shrinking some coefficients to zero.
3. *Elastic Net* â€“ Combines L1 and L2 penalties for balanced regularization.

## ğŸ“– About Regularization
Regularization is a method to *prevent overfitting* in machine learning models by adding a penalty term to the loss function.  
- *Ridge*: Keeps all features but reduces their magnitude.  
- *Lasso*: Eliminates less important features entirely.  
- *Elastic Net*: Offers a trade-off between Ridge and Lasso benefits.

## ğŸ›  Technologies Used
- Python 
- Pandas
- NumPy
- Matplotlib
- Scikit-Learn

## ğŸ“‚ Projects Included
### 1ï¸âƒ£ Ridge Regression
- Predicts target variable while controlling coefficient size using L2 penalty.

### 2ï¸âƒ£ Lasso Regression
- Performs both prediction and feature selection using L1 penalty.

### 3ï¸âƒ£ Elastic Net
- Balances between Ridge and Lasso for more robust predictions.
